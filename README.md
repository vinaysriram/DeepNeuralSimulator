# Deep Neural Simulator

This repository provides lightweight abstractions for deep learning. The neural network class allows users to train and test deep feed-forward neural networks for classification or regression. Training is done through gradient descent with L2 regularization and gradients are computed via backpropagation. Supported activation functions include ReLU, Logistic, Tanh, and Softmax. The tutorial provided [here](http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/) details the approach used in this implementation. The neural pool class is intended purely for regression. Spiking neuron pools are a great tool for nonlinear function approximation. They are trained such that the weighted sum of multidimensional tuning curves closely resembes the desired function. The stages of training are (1) generating different neurons with random parameters, (2) computing the tuning curves by running each neuron over the function's input domain and (3) solving a least squares regression problem to compute the optimal tuning curve weights. The neural activations are generated by simulating [Izhikevich-model spiking neurons](https://www.izhikevich.org/publications/spikes.htm). The MATLAB scripts provided can be used to visualize the differences between the tuning curves for different neuron types. The following neuron types are supported.

1. Regular Spiking Neuron
2. Intrinsically Bursting Neuron
3. Chattering Neuron
4. Fast Spiking Neuron
5. Thalmo-Cortical Neuron
6. Resonator Neuron
7. Low-Threshold Spiking Neuron

A data utils library is provided that can be used to generate, import, and export datasets for model training and evaluation. Several simple regression and classification datasets are implemented. Note that the regression datasets have two-dimensional inputs and one-dimensional outputs, while the classification datasets have two-dimensional inputs and three-dimensional (one-hot) outputs.

### Building the Code

This code has been tested on Ubuntu 18.04. Install [Bazel](https://docs.bazel.build/versions/master/install-ubuntu.html) and build using `bazel build //...`.

### Running the Examples

The network example app trains a deep neural network with one 25-neuron hidden layer to  classify points into one of three classes in a concentric dataset. This network is trained for 50 epochs with a learning rate of 0.01 and regularization constant of 0.0001. The original function (1000 datapoints) is dumped into `/tmp/true.txt` and the model-predicted function (also 1000 datapoints) is dumped into `/tmp/eval.txt`.

`./bazel-bin/example-apps/network-example-app`

The pool example app trains a pool of 25 regular spiking neurons to compute a multidimensional sinusoid function. The original function (1000 datapoints) is dumped into `/tmp/true.txt` and the model-predicted function (also 1000 datapoints) is dumped into `/tmp/eval.txt`.

`./bazel-bin/example-apps/pool-example-app`

If `python3` is installed (the default Python 3.6 installation that comes with Ubuntu 18.04 should be fine), you can view the original dataset together with the model-predicted function (for regression) or decision boundary (for classification) by including the path to the visualizer script as an argument to the example app.

`./bazel-bin/example-apps/network-example-app scripts/visualizer.py`

`./bazel-bin/example-apps/pool-example-app scripts/visualizer.py`
